---
layout: post
title: "머신러닝 개념에 발담구기"
subtitle: 1차 정리
date: 2020-06-17 1:32:28 -0400
cover-img: /assets/img/startup.jpg
tags: [machine_learning, perceptron, adaline]
---

# 퍼셉트론이란?

![image](https://user-images.githubusercontent.com/37768791/84805794-c0112a00-b03f-11ea-9198-3a13d9e8592e.png)

위 사진을 보면 y로 2개의 노드가 연결되어 있는 걸 볼 수 있습니다. 여기서 y노드를 퍼셉트론이라고 합니다. 결국 그림과 같이 다수의 신호를 받아서 하나의 신호로 출력하는 것입니다.

## 논리 게이트들

- AND 게이트
- NAND 게이트
- OR 게이트
- XOR 게이트

<br>

# 아달린이란?

ADALINE = `ADA`ptive `LI`near `NE`uron의 줄임말로 적응형 선형 뉴런을 의미합니다.

간단히 얘기하면 퍼셉트론의 향상된 버전입니다.

그럼 퍼셉트론과 어떤 차이점이 있을까요?

- 비용함수
- 선형 활성화 함수

<center>
<img src="https://user-images.githubusercontent.com/37768791/84806771-2cd8f400-b041-11ea-8443-7f90f1d247a9.png">
</center>

그림에서 볼 수 있듯이 시그마 아이콘이 있는 최종 입력 함수 다음에 선형 활성화 함수(activation function)가 추가된 것을 볼 수 있습니다.

그래서 아달린 알고리즘은 `진짜 클래스 레이블(관측값)`과 `선형 활성화 함수의 실수 출력 값`을 비교합니다.

<br>

## 경사하강법은 무엇인가?

<br>

왜 아달린에 `경사하강법`이 나왔을까요?

경사하강법은 비용함수(에러)를 `최소화`하기 위한 방법 중 하나입니다. 아까 설명했듯이 아달린에서 비용함수를 사용하기 때문이죠.

`[원리]`

SSE(잔차제곱합)으로 가중치 학습에 사용될 비용함수를 정의합니다.

비용함수 = sum(관측값 - 선형 활성화 함수 출력값) / 2

일단 비용함수는 구했는데 그럼 최소화는 어떻게 시킬까요?

<center>
<img src="https://user-images.githubusercontent.com/37768791/84807485-47f83380-b042-11ea-8d62-a904d60b36d8.png">
</center>

새로 가중치를 업데이트해서 점점 가중치를 줄이는 과정인데 그럼 가중치 업데이트는?

새로운 가중치 = -학습률 \* 비용함수

- 학습률은 어떻게 정해지는가?

  에포크 수를 조정해서 그래프를 그려가면서 최소화하는 구간으로 가는지 시각적으로 확인해가면서 정합니다.
